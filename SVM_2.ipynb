{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhrcl+X3pWteKN8nH0a90G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIVYA14797/Machine-Learning/blob/main/SVM_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LK41t4cJVUS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is relationship between polynomial functions and kernel functions in machine learning algorithm ?\n",
        "\n"
      ],
      "metadata": {
        "id": "sc6222gJJsBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial functions and kernel functions are both used in machine learning algorithms, particularly in the context of support vector machines (SVMs) and kernel methods. Here's a brief overview of their relationship:\n",
        "\n",
        "1. Polynomial functions:\n",
        "* Polynomial functions are mathematical functions of the form f(x)=$a_nx^n+a_(n-1)x^(n-1)+....+a_1x+a_0$ , where x is the independent variable and $a_0,a_1,....,a_n$ are coefficients.\n",
        "* In machine learning, polynomial functions are often used as basis functions to transform the input features into a higher-dimensional space. This transformation can help in capturing complex relationships between features.\n",
        "* In the context of SVMs, polynomial kernels compute the similarity between two samples as the inner product of the transformed feature vectors in a higher-dimensional space.\n",
        "\n",
        "2. Kernel functions:\n",
        "\n",
        "* Kernel functions are used to measure similarity between pairs of data points in a feature space without explicitly transforming them into that space.\n",
        "* A kernel function K($x_i,x_j$) takes two input data points $x_i$and $x_j$ and computes their similarity, often referred to as the kernel trick.\n",
        "* The most common kernel functions include linear kernel, polynomial kernel, Gaussian (RBF) kernel, sigmoid kernel, etc.\n",
        "* Polynomial kernel is one type of kernel function which computes the similarity between two samples using a polynomial function.\n",
        "\n",
        "The relationship between polynomial functions and polynomial kernel functions in machine learning is that the polynomial kernel function essentially computes the similarity between data points in a higher-dimensional space induced by a polynomial transformation of the original feature space. This allows SVMs to capture non-linear relationships between features by implicitly mapping the data into a higher-dimensional space where linear separation may be more feasible.\n",
        "\n",
        "In summary, polynomial functions are used to transform input features into a higher-dimensional space in a deterministic way, while polynomial kernel functions compute similarities between data points in the original space, effectively achieving a similar result to transforming features into higher dimensions but without the computational cost of explicitly doing so.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XE3NPF5_JzCk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uk34tT5vNvnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How can we implement an SVM with a polynomial kernel in python using scikit-learn ?"
      ],
      "metadata": {
        "id": "-ypOcXWZNwKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can implement an SVM with a polynomial kernel in Python using scikit-learn library."
      ],
      "metadata": {
        "id": "MVCUU8AzN9a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "TXA5H915OPXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "sdi2FQnROd3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an SVM classifier with a polynomial kernel\n",
        "svm_classifier = SVC(kernel='poly', degree=3)  # 'degree' parameter specifies the degree of the polynomial kernel\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4Wy75kPIOnzk",
        "outputId": "64cdeb3f-86d1-4af9-ff4c-fb09103d04e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='poly')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKJdnrs6OvHd",
        "outputId": "94f6dff6-ee01-4d7a-b76e-22739f06b8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7t24XbaO5QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How does increasing the value of epsilon affect the number of support vectors in SVR ?"
      ],
      "metadata": {
        "id": "5FW6c9G_O6Gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Support Vector Regression (SVR), the epsilon parameter (ε) determines the margin of tolerance around the predicted value. It defines a margin within which no penalty is associated with errors, essentially controlling the tube width within which errors are ignored.\n",
        "\n",
        "As we increase the value of epsilon:\n",
        "\n",
        "1. Wider Margin:\n",
        "\n",
        "* A larger epsilon results in a wider margin around the predicted value. This means that SVR tolerates larger errors before considering them as part of the loss function.\n",
        "* With a wider margin, the SVR model allows more data points to fall within the margin of tolerance without being penalized.\n",
        "\n",
        "2. More Support Vectors:\n",
        "\n",
        "* Support vectors are the data points that lie on the margin boundary or within the margin with non-zero coefficients.\n",
        "* When epsilon is increased, more data points can fall within the margin of tolerance without penalty, which means more data points are likely to become support vectors.\n",
        "* This happens because the wider margin allows more flexibility in fitting the training data while still satisfying the margin requirements.\n",
        "\n",
        "Therefore, increasing the value of epsilon tends to increase the number of support vectors in SVR. Conversely, decreasing the value of epsilon would result in a narrower margin, leading to fewer support vectors as the model becomes more strict in enforcing the margin requirements and penalizing errors outside the margin.\n",
        "\n",
        "However, it's important to note that the exact impact of epsilon on the number of support vectors can vary depending on other factors such as the complexity of the data, the choice of kernel function, and other hyperparameters like C and gamma."
      ],
      "metadata": {
        "id": "Nn9H407xPF58"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mhti3qB-Pf7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does the choice of kernel function , Cparameter , epsilon parameter and gamma parameter affect the performance of SVR ? Can you explain how each parameter works and provide examples of when you might want to increase oe decrease its value ?"
      ],
      "metadata": {
        "id": "EUk5UgAMPgcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Regression (SVR) is a type of Support Vector Machine (SVM) algorithm used for regression tasks. The performance of SVR can be significantly affected by the choice of kernel function and various hyperparameters such as C, epsilon, and gamma. Let's discuss each parameter and how it affects SVR performance:\n",
        "\n",
        "1. Kernel Function:\n",
        "\n",
        "* The kernel function determines the type of mapping that transforms the input data into a higher-dimensional space.\n",
        "* Common kernel functions include linear, polynomial, radial basis function (RBF), sigmoid, etc.\n",
        "* Choice of kernel function depends on the nature of the data and the problem at hand:\n",
        " * Linear kernel: Suitable for linear relationships between features.\n",
        " * Polynomial kernel: Suitable for data with complex, non-linear relationships. Higher degrees can capture more complex relationships, but be cautious of overfitting.\n",
        " * RBF kernel: Suitable for data with non-linear and non-linearly separable patterns. It is highly flexible but can be prone to overfitting if gamma is too large.\n",
        "\n",
        "2. C Parameter:\n",
        "\n",
        "* C is the regularization parameter that controls the trade-off between maximizing the margin and minimizing the training error.\n",
        "* A smaller C value allows for a larger margin, potentially resulting in a smoother decision boundary. This can help prevent overfitting, especially if the data is noisy or if there are outliers.\n",
        "* Conversely, a larger C value penalizes misclassifications more heavily, potentially leading to a tighter decision boundary. This can improve accuracy on training data but may lead to overfitting.\n",
        "\n",
        "3. Epsilon Parameter:\n",
        "\n",
        "* Epsilon (ε) is the margin of tolerance around the predicted value.\n",
        "* It defines a margin of tolerance where no penalty is associated with errors that fall within this margin. SVR will ignore errors smaller than ε.\n",
        "* A smaller epsilon allows for a smaller margin of tolerance, which means the model will try to fit the data more closely, potentially leading to overfitting.\n",
        "* A larger epsilon allows for a larger margin of tolerance, which can result in a more robust model that generalizes better to unseen data but may sacrifice accuracy on the training data.\n",
        "\n",
        "4. Gamma Parameter:\n",
        "\n",
        "* Gamma (γ) defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’.\n",
        "* It is a parameter of the RBF kernel and controls the smoothness of the decision boundary.\n",
        "* A smaller gamma value results in a smoother decision boundary, which can help prevent overfitting but might lead to underfitting if set too low.\n",
        "* A larger gamma value makes the model more sensitive to the training data, potentially leading to overfitting. It can capture intricate details of the training data but may not generalize well to unseen data.\n",
        "\n",
        "Examples of when to increase or decrease each parameter:\n",
        "\n",
        "* Increase C when the training data is not well-separated and you want to emphasize correct classification more.\n",
        "Decrease C when the model is overfitting or when you have noisy data.\n",
        "* Increase epsilon to allow for more tolerance of errors, especially if the data has noise or outliers.\n",
        "* Decrease epsilon if you want the model to fit the training data more closely.\n",
        "* Increase gamma when you have a small number of training samples or when the data is well-separated and you want a more complex decision boundary.\n",
        "* Decrease gamma if you have a large number of training samples or if the decision boundary is too complex, leading to overfitting.\n",
        "\n",
        "It's important to note that the choice of parameters often involves experimentation and tuning, and there's no one-size-fits-all solution. Cross-validation and grid search techniques can help in finding the optimal values for these parameters."
      ],
      "metadata": {
        "id": "7es7w7i_P1yC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lE8AsCblQ_Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Assignment: Import dataset from scikit-learn  .( Train , Test Scaling , Normalization ,SVC classifier and train , Prediction ,Metrics , RandomizedCV to the dataset .)"
      ],
      "metadata": {
        "id": "6sRuCzkERA1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "s-bGpM2iRgd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling (standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_LsOsx1RixV",
        "outputId": "33a0ac39-921b-4c6a-b843-5a0aad8682a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.35451684, -0.58505976,  0.55777524,  0.02224751],\n",
              "       [-0.13307079,  1.65083742, -1.16139502, -1.17911778],\n",
              "       [ 2.30486738, -1.0322392 ,  1.8185001 ,  1.49058286],\n",
              "       [ 0.23261993, -0.36147005,  0.44316389,  0.4227026 ],\n",
              "       [ 1.2077952 , -0.58505976,  0.61508092,  0.28921757],\n",
              "       [-0.49876152,  0.75647855, -1.27600637, -1.04563275],\n",
              "       [-0.2549677 , -0.36147005, -0.07258719,  0.15573254],\n",
              "       [ 1.32969211,  0.08570939,  0.78699794,  1.49058286],\n",
              "       [ 0.47641375, -1.92659808,  0.44316389,  0.4227026 ],\n",
              "       [-0.01117388, -0.80864948,  0.09932984,  0.02224751],\n",
              "       [ 0.84210448,  0.30929911,  0.78699794,  1.09012776],\n",
              "       [-1.23014297, -0.13788033, -1.33331205, -1.44608785],\n",
              "       [-0.37686461,  0.98006827, -1.39061772, -1.31260282],\n",
              "       [-1.10824606,  0.08570939, -1.27600637, -1.44608785],\n",
              "       [-0.86445224,  1.65083742, -1.27600637, -1.17911778],\n",
              "       [ 0.59831066,  0.53288883,  0.55777524,  0.55618763],\n",
              "       [ 0.84210448, -0.13788033,  1.18813767,  1.35709783],\n",
              "       [-0.2549677 , -1.25582892,  0.09932984, -0.11123753],\n",
              "       [-0.13307079, -0.58505976,  0.44316389,  0.15573254],\n",
              "       [ 0.72020757, -0.58505976,  1.07352632,  1.35709783],\n",
              "       [-1.35203988,  0.30929911, -1.2187007 , -1.31260282],\n",
              "       [ 0.35451684, -0.13788033,  0.67238659,  0.8231577 ],\n",
              "       [-0.98634915,  0.75647855, -1.2187007 , -1.04563275],\n",
              "       [ 0.72020757, -0.58505976,  1.07352632,  1.22361279],\n",
              "       [ 2.5486612 ,  1.65083742,  1.53197172,  1.09012776],\n",
              "       [ 1.08589829, -0.13788033,  0.84430362,  1.49058286],\n",
              "       [ 1.08589829, -1.25582892,  1.18813767,  0.8231577 ],\n",
              "       [ 1.2077952 ,  0.30929911,  1.24544335,  1.49058286],\n",
              "       [-1.23014297, -0.13788033, -1.33331205, -1.17911778],\n",
              "       [-1.23014297,  0.08570939, -1.2187007 , -1.31260282]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature normalization (min-max scaling)\n",
        "normalizer = MinMaxScaler()\n",
        "X_train_normalized = normalizer.fit_transform(X_train)\n",
        "X_test_normalized = normalizer.transform(X_test)\n",
        "X_test_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieUwBzB4Rn_E",
        "outputId": "8da65b6f-fadb-43ee-ef05-eead91759809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52941176, 0.33333333, 0.64912281, 0.45833333],\n",
              "       [0.41176471, 0.75      , 0.12280702, 0.08333333],\n",
              "       [1.        , 0.25      , 1.03508772, 0.91666667],\n",
              "       [0.5       , 0.375     , 0.61403509, 0.58333333],\n",
              "       [0.73529412, 0.33333333, 0.66666667, 0.54166667],\n",
              "       [0.32352941, 0.58333333, 0.0877193 , 0.125     ],\n",
              "       [0.38235294, 0.375     , 0.45614035, 0.5       ],\n",
              "       [0.76470588, 0.45833333, 0.71929825, 0.91666667],\n",
              "       [0.55882353, 0.08333333, 0.61403509, 0.58333333],\n",
              "       [0.44117647, 0.29166667, 0.50877193, 0.45833333],\n",
              "       [0.64705882, 0.5       , 0.71929825, 0.79166667],\n",
              "       [0.14705882, 0.41666667, 0.07017544, 0.        ],\n",
              "       [0.35294118, 0.625     , 0.05263158, 0.04166667],\n",
              "       [0.17647059, 0.45833333, 0.0877193 , 0.        ],\n",
              "       [0.23529412, 0.75      , 0.0877193 , 0.08333333],\n",
              "       [0.58823529, 0.54166667, 0.64912281, 0.625     ],\n",
              "       [0.64705882, 0.41666667, 0.84210526, 0.875     ],\n",
              "       [0.38235294, 0.20833333, 0.50877193, 0.41666667],\n",
              "       [0.41176471, 0.33333333, 0.61403509, 0.5       ],\n",
              "       [0.61764706, 0.33333333, 0.80701754, 0.875     ],\n",
              "       [0.11764706, 0.5       , 0.10526316, 0.04166667],\n",
              "       [0.52941176, 0.41666667, 0.68421053, 0.70833333],\n",
              "       [0.20588235, 0.58333333, 0.10526316, 0.125     ],\n",
              "       [0.61764706, 0.33333333, 0.80701754, 0.83333333],\n",
              "       [1.05882353, 0.75      , 0.94736842, 0.79166667],\n",
              "       [0.70588235, 0.41666667, 0.73684211, 0.91666667],\n",
              "       [0.70588235, 0.20833333, 0.84210526, 0.70833333],\n",
              "       [0.73529412, 0.5       , 0.85964912, 0.91666667],\n",
              "       [0.14705882, 0.41666667, 0.07017544, 0.08333333],\n",
              "       [0.14705882, 0.45833333, 0.10526316, 0.04166667]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an SVC classifier (using scaled features)\n",
        "svc_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  # Example parameters\n",
        "svc_classifier.fit(X_train_scaled, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5_9J_PptRtr1",
        "outputId": "2433f7a3-3b8d-4750-ab69-79815e51e7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_scaled = svc_classifier.predict(X_test_scaled)\n",
        "y_pred_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixsGU6HcR1oF",
        "outputId": "18b26a52-6bde-4c3f-fa74-0a6aeb004e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate metrics\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(\"Accuracy (scaled):\", accuracy_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwg2AV2TR_ym",
        "outputId": "164a736a-ab7b-4e4f-c696-dfde7b945ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (scaled): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(\"Classification Report (scaled):\\n\", classification_report(y_test, y_pred_scaled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCDDmy4YSFkS",
        "outputId": "d2ecc05a-42eb-4ed0-db84-1cf8b33dbb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (scaled):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "randomized_search = RandomizedSearchCV(SVC(), param_distributions, n_iter=10, cv=5, random_state=42)\n",
        "randomized_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_params = randomized_search.best_params_\n",
        "best_svc_classifier = randomized_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf7prn5XSMHa",
        "outputId": "ca4c5912-d0a9-4d72-e1e2-9c6dbe2b42e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'kernel': 'linear', 'gamma': 'scale', 'C': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the best model\n",
        "y_pred_best = best_svc_classifier.predict(X_test_scaled)\n",
        "y_pred_best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuxZDEL6SYi0",
        "outputId": "889ff8f1-5b43-4524-cfd5-50301f775f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate metrics with the best model\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "print(\"Accuracy (best model):\", accuracy_best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvQ-31obSeAN",
        "outputId": "2512e5f9-ac8a-4b43-a583-e7ddfdeaa38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (best model): 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report with the best model\n",
        "print(\"Classification Report (best model):\\n\", classification_report(y_test, y_pred_best))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3jzJlwfSkjU",
        "outputId": "f744f655-73c4-4ecb-cb3b-f6a0c57f44cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (best model):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}